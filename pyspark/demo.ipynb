{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2757dfd6362a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.78.22.76:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "a: List[int] = ['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'help']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class A(object):\n",
    "    def help(self):\n",
    "        self: A = self\n",
    "    \n",
    "print(dir(A))\n",
    "a = A()\n",
    "type(a).__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取本地文件，创建临时表\n",
    "\n",
    "使用 sql 查询，统计，可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+------+------+----+\n",
      "|          _c0|  _c1|   _c2|   _c3| _c4|\n",
      "+-------------+-----+------+------+----+\n",
      "| 310231212030|35874|610429|陕西省|西北|\n",
      "|3102312112312| 9767|610528|陕西省|西北|\n",
      "|3102312112310|19650|610528|陕西省|西北|\n",
      "|3102312112313|25445|610528|陕西省|西北|\n",
      "|3102312112311| 6825|610528|陕西省|西北|\n",
      "+-------------+-----+------+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Test\") \\\n",
    "    .config('spark.default.parallelism','2') \\\n",
    "    .config('spark.executor.cores','2') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"com.databricks.spark.csv\") \\\n",
    ".option(\"delimiter\", \"\\t\") \\\n",
    ".load(\"/Users/andyzhuang/git/maps_arch/road_sampling/data/grid_length.csv\")\n",
    "\n",
    "df.show(5)\n",
    "df.createTempView(\"tempViewName\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+-----------+\n",
      "|   c|        region|       dist|\n",
      "+----+--------------+-----------+\n",
      "|   1|澳门特别行政区|    16778.0|\n",
      "| 924|        海南省| 1.450653E7|\n",
      "|1487|    西藏自治区|1.4597324E7|\n",
      "|1266|宁夏回族自治区|2.0415487E7|\n",
      "|1740|        青海省| 2.086058E7|\n",
      "|1271|        天津市|2.2176234E7|\n",
      "|1296|        上海市|2.3644975E7|\n",
      "|1760|        北京市|3.0573731E7|\n",
      "|2347|        重庆市|3.7011754E7|\n",
      "|3109|        吉林省|3.9025639E7|\n",
      "|3247|        甘肃省|4.2083765E7|\n",
      "|4709|      黑龙江省|5.1785284E7|\n",
      "|3857|        贵州省|6.0030273E7|\n",
      "|3871|        江西省|6.1545331E7|\n",
      "|3888|        福建省|6.1804045E7|\n",
      "|4180|广西壮族自治区|6.3315192E7|\n",
      "|4278|        陕西省|6.6152502E7|\n",
      "|4201|        山西省|6.6718433E7|\n",
      "|4789|        云南省|6.9052626E7|\n",
      "|4580|        辽宁省|6.9871914E7|\n",
      "+----+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "groupby_df1 = spark.sql(\"select count(1) c,_c3 region,sum(_c1) dist from tempViewName group by _c3 order by dist\")\n",
    "groupby_df1.show()\n",
    "rows = groupby_df1.collect()\n",
    "region_list = []\n",
    "dist_list = []\n",
    "for r in rows:\n",
    "    region_list.append(r.region)\n",
    "    dist_list.append(r.dist)\n",
    "\n",
    "# import matplotlib.pyplot as plt \n",
    "# plt.rcParams['font.family'] = ['sans-serif']\n",
    "# plt.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "# plt.bar(region_list, dist_list)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+----+---------------+---+\n",
      "|          _c0|   _c1| _c2|            _c3|_c4|\n",
      "+-------------+------+----+---------------+---+\n",
      "|     13194124|610429|西北|310231212030203|364|\n",
      "|9100051363998|610528|西北|310231211231222| 15|\n",
      "|9100042483150|610827|西北|310233120101302| 11|\n",
      "|9100055577627|610524|西北|310231302301223| 47|\n",
      "|9100042071344|610326|西北|310231023233022|224|\n",
      "+-------------+------+----+---------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = spark.read.format(\"com.databricks.spark.csv\") \\\n",
    ".option(\"delimiter\", \"\\t\") \\\n",
    ".load(\"/Users/andyzhuang/tmp/link_grid_lenth_zoom15_version2.csv\")\n",
    "\n",
    "df_raw.show(5)\n",
    "df_raw.createTempView(\"tmp_link_grid_elem\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+------+------+\n",
      "|         k12|    len|  code|region|\n",
      "+------------+-------+------+------+\n",
      "|310211232321|39999.0|520000|  西南|\n",
      "|312112001120|39997.0|220000|  东北|\n",
      "|312130003221|39996.0|150000|  东北|\n",
      "|310033332321|39994.0|440000|  华南|\n",
      "|310302231210|39992.0|420000|  华中|\n",
      "+------------+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoom12_le40 = spark.sql(\"select * from \\\n",
    "                            (select key k12, sum(_c4) len,concat(substr(max(_c1),0,2), '0000') code,max(_c2) region from \\\n",
    "                            (select substr(_c3,0,12) key, * from tmp_link_grid_elem)a \\\n",
    "                            group by key )a \\\n",
    "                            where len<=40*1000 \\\n",
    "                            order by len desc\")\n",
    "zoom12_le40 = zoom12_le40.alias(\"zoom12_le40\")\n",
    "zoom12_le40.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+--------------+-------------+------+----+---------------+---+\n",
      "|         k12|          k13|           k14|          _c0|   _c1| _c2|            _c3|_c4|\n",
      "+------------+-------------+--------------+-------------+------+----+---------------+---+\n",
      "|310231212030|3102312120302|31023121203020|     13194124|610429|西北|310231212030203|364|\n",
      "|310231211231|3102312112312|31023121123122|9100051363998|610528|西北|310231211231222| 15|\n",
      "|310233120101|3102331201013|31023312010130|9100042483150|610827|西北|310233120101302| 11|\n",
      "|310231302301|3102313023012|31023130230122|9100055577627|610524|西北|310231302301223| 47|\n",
      "|310231023233|3102310232330|31023102323302|9100042071344|610326|西北|310231023233022|224|\n",
      "+------------+-------------+--------------+-------------+------+----+---------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_df = spark.sql(\"select substr(_c3,0,12) k12, substr(_c3,0,13) k13,substr(_c3,0,14) k14,* from tmp_link_grid_elem\")\n",
    "t_df = t_df.alias(\"t_df\")\n",
    "t_df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+------+------+\n",
      "|          k13|    len|  code|region|\n",
      "+-------------+-------+------+------+\n",
      "|3102232133211|40000.0|620200|  西北|\n",
      "|3102311213031|39999.0|611023|  西北|\n",
      "|3103223301221|39996.0|110117|  华北|\n",
      "|3103230001220|39995.0|370781|  华北|\n",
      "|3102102102232|39994.0|530103|  西南|\n",
      "|3103210101201|39990.0|321283|  华东|\n",
      "|3121101222302|39989.0|220282|  东北|\n",
      "|3103212033122|39983.0|371102|  华北|\n",
      "|3103032333210|39977.0|320582|  华东|\n",
      "|3121122122211|39977.0|230223|  东北|\n",
      "|3103032131232|39972.0|330481|  华东|\n",
      "|3103221113120|39966.0|370321|  华北|\n",
      "|3102121332130|39965.0|500116|  西南|\n",
      "|3102332223100|39964.0|150802|  东北|\n",
      "|3102312212001|39962.0|621002|  西北|\n",
      "|3103032133230|39960.0|330402|  华东|\n",
      "|3103202103023|39957.0|410204|  华中|\n",
      "|3103003110111|39953.0|350603|  华东|\n",
      "|3103201312032|39952.0|341323|  华中|\n",
      "|3103221100302|39951.0|370105|  华北|\n",
      "+-------------+-------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# k13\n",
    "\n",
    "\n",
    "zoom13_le40 = t_df.join(zoom12_le40, zoom12_le40.k12==t_df.k12, 'left').where(\"zoom12_le40.k12 is null\").select(\"t_df.*\") \\\n",
    ".groupby(t_df.k13).agg({'_c4': 'sum', '_c1': 'min', '_c2': 'min'}).toDF('k13', 'len', 'code', 'region') \\\n",
    ".where(\"len<=40*1000\")\n",
    "zoom13_le40 = zoom13_le40.orderBy(zoom13_le40.len.desc())\n",
    "zoom13_le40 = zoom13_le40.alias(\"zoom13_le40\")\n",
    "zoom13_le40.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------+------+\n",
      "|           k14|    len|  code|region|\n",
      "+--------------+-------+------+------+\n",
      "|31030303202001|39995.0|330702|  华东|\n",
      "|31032022213102|39992.0|140402|  华北|\n",
      "|31032202002003|39992.0|140107|  华北|\n",
      "|31021231112123|39987.0|500112|  西南|\n",
      "|31030200232011|39985.0|430104|  华中|\n",
      "+--------------+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoom13_le40 = zoom13_le40.alias(\"zoom13_le40\")\n",
    "# k14\n",
    "zoom14_le40 = t_df.join(zoom13_le40, zoom13_le40.k13==t_df.k13, 'left').where(\"zoom13_le40.k13 is null\") \\\n",
    ".select(\"t_df.*\") \\\n",
    ".groupby(t_df.k14).agg({'_c4': 'sum', '_c1': 'min', '_c2': 'min'}).toDF('k14', 'len', 'code', 'region') \\\n",
    ".where(\"len<=40*1000\")\n",
    "zoom14_le40 = zoom14_le40.orderBy(zoom14_le40.len.desc())\n",
    "zoom14_le40 = zoom14_le40.alias(\"zoom14_le40\")\n",
    "zoom14_le40.show(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+------+------+\n",
      "|            k15|    len|  code|region|\n",
      "+---------------+-------+------+------+\n",
      "|310300003221210|36658.0|440104|  华南|\n",
      "|310300010223121|34310.0|440304|  华南|\n",
      "|310300010223103|33163.0|440304|  华南|\n",
      "|310303320330020|31185.0|310101|  华东|\n",
      "|310303032312031|30720.0|330782|  华东|\n",
      "+---------------+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zoom14_le40 = zoom14_le40.alias(\"zoom14_le40\")\n",
    "# k15\n",
    "zoom15_le40 = t_df.join(zoom14_le40, zoom14_le40.k14==t_df._c3, 'left').where(\"zoom14_le40.k14 is null\") \\\n",
    ".select(\"t_df.*\") \\\n",
    ".groupby(t_df._c3).agg({'_c4': 'sum', '_c1': 'min', '_c2': 'min'}).toDF('k15', 'len', 'code', 'region') \\\n",
    ".where(\"len<=40*1000\")\n",
    "zoom15_le40 = zoom15_le40.orderBy(zoom15_le40.len.desc())\n",
    "zoom15_le40 = zoom15_le40.alias(\"zoom15_le40\")\n",
    "zoom15_le40.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union\n",
    "result_df = zoom12_le40.toDF('key','len', 'code', 'region') \\\n",
    ".union(zoom13_le40.toDF('key','len', 'code', 'region')) \\\n",
    ".union(zoom14_le40.toDF('key','len', 'code', 'region')) \\\n",
    ".union(zoom15_le40.toDF('key','len', 'code', 'region')) \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376826\n",
      "+-------------+\n",
      "|     sum(len)|\n",
      "+-------------+\n",
      "|4.847289349E9|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = result_df.count()\n",
    "print(c)\n",
    "result_df.agg({'len': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
